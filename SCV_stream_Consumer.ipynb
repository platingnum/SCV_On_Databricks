{"cells":[{"cell_type":"markdown","source":["## Single Customer View\nSteps involved in creating SCV\n### 1. Build base UserSCV table  \n> 1.1. Cleanse the data (Validate Email, format Phone No, Landline No). This is done by calling function on each row in dataFrame. \n\n> 1.2. An intermediate table is created to hold validated/cleanse data, before transforming original data. \n\n> 1.3. Create additional fields by combining base fields (FirstName, UserName, LastName, DOB). Some of the combinations are as follows:\n            * Firstname_Lastname_RegIP\t\t\n            * Firstname_Lastname_LastIP\t\t\n            * Firstname_Lastname_Username\t\t\n            * Firstname_DOB_City\t\t\t\t\n            * Firstname_Postcode\t\t\t\t\n            * Firstname_Mobilephone\t\t\t\n            * DOB_Postcode\t\t\t\t\t\n            * Address1_Postcode\t\t\t\t\n            * Firstname_Lastname_Address1_City\n> Create UserSCV hive table with base fields and additional fields.\n\n\n### 2. For each data load, perform check against base UserCSV. A record is considered same if it meets any one of the criteria:\n| FirstName| Lastname | DOB  | Email | Postcode | Result   |\n| :-------:| :-------:| :---:| :----:| :-------:| :-------:|\n| X|X|X|X|X|**MATCH**|\n|  |X|X|X|X|**MATCH**|\n| X| |X|X|X|**MATCH**|\n| X|X| |X|X|**MATCH**|\n| X|X|X| |X|**MATCH**|\n| X|X|X|X| |**MATCH**|\n\n**Minimal conditions for match: **\n\n| S.No| Criteria|\n| :--:| :------:|\n|1.|Firstname + IP Address|\n|2.|Firstname + Username|\n\n### 2.1. Data is given as  csv file and converted into Table with cleansed data. Join is performed with UserSCV table and loaded data and eac criteria mentioned above is checked to determine the match with existing Master UserSCV table.  \n### 3. If matched records found, insert new version of user record with Related Id into UserSCV table. \n\n\n####  Issues faced while building UserSCV\n\n1. **Pre-processing data**: Pre-processing and cleansing posed as main milestone when building base UserSCV table. A function is called on each row to pre-process the data.\n2. **Transforming data:** Transforming pre-process data before converting into UserSCV table involves adding many new fields by combining different combinations of exisitin field and assigning each row with unique Id. This unique Id will be used as \"Related Id\" when matching user record is found in UserSCV table."],"metadata":{}},{"cell_type":"code","source":["# import libraries\nfrom pyspark.sql.types import StringType, IntegerType, TimestampType, DateType, DoubleType, StructType, StructField\nimport requests\nimport json\nimport re\nimport datetime\nimport schedule\nimport time\nimport pandas as pd\nimport phonenumbers\nfrom pyspark.sql import SQLContext, Row\nfrom pyspark.sql.functions import  col\nfrom pyspark.sql.functions import unix_timestamp, from_unixtime\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import monotonically_increasing_id"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# schema for SCV User Table \nuser_schema = StructType([\n            StructField(\"id\", IntegerType(), False),\n            StructField(\"Userid\", IntegerType(), True),\n            StructField(\"SkinID\", StringType(), True),\n            StructField(\"username\", StringType(), True),\n            StructField(\"first_name\", StringType(), True),\n            StructField(\"last_name\", StringType(), True),\n            StructField(\"email\", StringType(), True),\n            StructField(\"gender\", StringType(), True), \n            StructField(\"ip_address\", StringType(), True), \n            StructField(\"RegDate\", StringType(), True), \n            StructField(\"RegIP\", StringType(), True), \n            StructField(\"LastIP\", StringType(), True), \n            StructField(\"DOB\", StringType(), True), \n            StructField(\"Postcode\", StringType(), True), \n            StructField(\"MobilePhone\", StringType(), True), \n            StructField(\"Landline\", StringType(), True), \n            StructField(\"Address1\", StringType(), True),\n            StructField(\"City\", StringType(), True),\n            StructField(\"County\", StringType(), True),\n            StructField(\"Country\", StringType(), True),\n            StructField(\"SelfExcludedUntil\", StringType(), True),\n            StructField(\"Status\", StringType(), True)])\n            "],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# schema for incoming stream \nstream_schema = StructType([\n            StructField(\"id\", IntegerType(), False),\n            StructField(\"Userid\", IntegerType(), True),\n            StructField(\"SkinID\", StringType(), True),\n            StructField(\"username\", StringType(), True),\n            StructField(\"first_name\", StringType(), True),\n            StructField(\"last_name\", StringType(), True),\n            StructField(\"email\", StringType(), True),\n            StructField(\"gender\", StringType(), True), \n            StructField(\"ip_address\", StringType(), True), \n            StructField(\"RegDate\", StringType(), True), \n            StructField(\"RegIP\", StringType(), True), \n            StructField(\"LastIP\", StringType(), True), \n            StructField(\"DOB\", StringType(), True), \n            StructField(\"Postcode\", StringType(), True), \n            StructField(\"MobilePhone\", StringType(), True), \n            StructField(\"Landline\", StringType(), True), \n            StructField(\"Address1\", StringType(), True),\n            StructField(\"City\", StringType(), True),\n            StructField(\"County\", StringType(), True),\n            StructField(\"Country\", StringType(), True),\n            StructField(\"SelfExcludedUntil\", StringType(), True),\n            StructField(\"Status\", StringType(), True),\n            StructField(\"batch\", StringType(), True)])\n# The batch field is added to show the batch for a record "],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# This function cleans the user row; it cleans the fields like MobilePhone, Email\ndef fixUserRow(c):\n    # get the Mobile field\n    number = c.MobilePhone\n\n    # initialize variables \n    is_valid_number = \"N\"\n    clean_number = None\n    number_type = None\n    valid_mail = None\n\n    p = None\n\n    if number is not None:\n        # Clean the Mobile Number first\n        try:\n            p = phonenumbers.parse(number, c.Country)\n\n            if phonenumbers.is_valid_number(p):\n                is_valid_number = \"Y\"\n            elif phonenumbers.truncate_too_long_number(p):\n                is_valid_number = \"Y\"\n            else:\n                is_valid_number = \"N\"\n\n            clean_number = \"%s%s\" % (p.country_code, p.national_number)\n            \n        except:\n            p = None\n\n    # clean up PhoneNumber\n    phone_no = c.Landline\n    if phone_no is not None:\n      phone_no = phone_no.replace('-', '')\n      if (len(phone_no) != 10):\n        phone_no = None\n    \n    # validate Email \n    if re.match(r\"^[A-Za-z0-9\\.\\+_-]+@[A-Za-z0-9\\._-]+\\.[a-zA-Z]*$\", c.email):\n      valid_mail = c.email\n    \n    return Row( \n\t\tid = c.id, \n        Userid = c.Userid, \t\t\t\n        SkinID = c.SkinID,\n        username = c.username,\n        first_name = c.first_name, \t\t\n        last_name = c.last_name,\t\n        email = valid_mail,\t\t\t\n        gender = c.gender,\t\t\t\n        ip_address = c.ip_address,\n        RegDate = c.RegDate,\n        RegIP = c.RegIP,\n\t\tLastIP = c.LastIP,\t\t\t\n\t\tDOB = c.DOB,\t\t\t\n\t\tPostcode = c.Postcode,\t\t\n\t\tMobilePhone = clean_number, \t\n\t\tLandline = phone_no, \t\t\n\t\tAddress1 = c.Address1,\t\t\n        City = c.City, \t\t\t\n\t\tCounty = c.County,\t\t\t\n\t\tCountry = c.Country, \t\t\n        SelfExcludedUntil = c.SelfExcludedUntil,\n\t\tStatus = c.Status\t\t\t\n    )\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# insert matching records into UserSCV table\ndef insertNewVersionOfUser(tableName):\n  df = spark.sql(\"select  * from \" + tableName)\n  dateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\n  # select max of id from userSCV table\n  lv = sqlContext.sql(\"select max(ID) as lastVal from UserSCV\").collect()\n  lastValue = lv[0][\"lastVal\"]\n  df_userSCV = df.select(\"ID\", \\\n                         \"Userid1\", \\\n                         \"SkinID1\", \\\n                         \"username1\", \\\n                         \"first_name1\", \\\n                         \"last_name1\", \\\n                         \"email1\", \\\n                         \"gender1\", \"ip_address1\", \"RegDate1\", \"RegIP1\", \\\n                         \"LastIP1\", \"DOB1\", \"Postcode1\", \"MobilePhone1\", \"Landline1\", \\\n                         \"Address11\", \"City1\", \"County1\", \"Country1\", \\\n                         \"SelfExcludedUntil1\", \"Status1\", \\\n                         \"EntityId\", \\\n                         \"OriginalEmail\", \\\n                         \"OriginalFirstname\", \\\n                         \"OriginalLastname\", \\\n                         \"OriginalRegDate\", \\\n                         \"OriginalDOB\", \\\n                         \"OriginalPostcode\", \\\n                         \"OriginalMobilePhone\", \\\n                         \"OriginalAddress1\", \\\n                         \"OriginalCity\", \\\n                         \"Firstname_Lastname_RegIP\", \\\n                         \"Firstname_Lastname_LastIP\", \\\n                         \"Firstname_Lastname_Username\", \\\n                         \"Firstname_DOB_City\",\\\n                         \"Firstname_Postcode\", \\\n                         \"Firstname_Mobilephone\", \\\n                         \"DOB_Postcode\",  \\\n                         \"Address1_Postcode\", \\\n                         \"Firstname_Lastname_Address1_City\")\n  #df_userSCV = df_userSCV.withColumnRenamed(\"ID\", \"RelatedID\") \n  df_userSCV = df_userSCV.withColumn(\"RelatedID\", col(\"ID\"))\n  df_userSCV = df_userSCV.withColumn(\"Load_date\", lit(dateTimeStr))\n  df_userSCV = df_userSCV.withColumn(\"LastModifiedDate\", lit(dateTimeStr))\n  df_userSCV = df_userSCV.withColumn(\"CompareStatus\", lit(0))\n   \n  #df_userSCV = df_userSCV.withColumn(\"ID\", monotonically_increasing_id() + lastValue)\n  df_userSCV = df_userSCV.select(\"ID\", \\\n                        col(\"Userid1\").alias(\"Userid\"), col(\"SkinID1\").alias(\"SkinID\"), \\\n                        col(\"username1\").alias(\"username\"), col(\"first_name1\").alias(\"first_name\"), \\\n                        col(\"last_name1\").alias(\"last_name\"), col(\"email1\").alias(\"email\"), \\\n                        col(\"gender1\").alias(\"gender\"), col(\"ip_address1\").alias(\"ip_address\"), \\\n                        col(\"RegDate1\").alias(\"RegDate\"), col(\"RegIP1\").alias(\"RegIP\"), \\\n                        col(\"LastIP1\").alias(\"LastIP\"), col(\"DOB1\").alias(\"DOB\"), \\\n                        col(\"Postcode1\").alias(\"Postcode\"), col(\"MobilePhone1\").alias(\"MobilePhone\"), \\\n                        col(\"Landline1\").alias(\"Landline\"), col(\"Address11\").alias(\"Address1\"), \\\n                        col(\"City1\").alias(\"City\"), col(\"County1\").alias(\"County\"), \\\n                        col(\"Country1\").alias(\"Country\"), col(\"SelfExcludedUntil1\").alias(\"SelfExcludedUntil\"), \\\n                        col(\"Status1\").alias(\"Status\"), \\\n                         \"RelatedID\", \\\n                         \"EntityId\", \\\n                         \"OriginalEmail\", \\\n                         \"OriginalFirstname\", \\\n                         \"OriginalLastname\", \\\n                         \"OriginalRegDate\", \\\n                         \"OriginalDOB\", \\\n                         \"OriginalPostcode\", \\\n                         \"OriginalMobilePhone\", \\\n                         \"OriginalAddress1\", \\\n                         \"OriginalCity\", \\\n                         \"Firstname_Lastname_RegIP\", \\\n                         \"Firstname_Lastname_LastIP\", \\\n                         \"Firstname_Lastname_Username\", \\\n                         \"Firstname_DOB_City\",\\\n                         \"Firstname_Postcode\", \\\n                         \"Firstname_Mobilephone\", \\\n                         \"DOB_Postcode\",  \\\n                         \"Address1_Postcode\", \\\n                         \"Firstname_Lastname_Address1_City\", \\\n                         \"Load_date\", \\\n                         \"LastModifiedDate\",\\\n                         \"CompareStatus\")\n\n  df_userSCV.write.insertInto(\"UserSCV\")\n  \n  "],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# This function converts the csv file to Spark Data Frame.\ndef getDataFrameFromStream(df, schema):\n   \n  df_new_load = df\n  from pyspark.sql.functions import col\n\n  \n  # cleanse the data\n  df_user_updated1 = df_new_load.rdd.map(lambda c: fixUserRow(c))\n  # change the column type now\n  df_new = sqlContext.createDataFrame(df_user_updated1, user_schema)\n  df_new = df_new.select (col(\"ID\").alias(\"ID1\"), col(\"Userid\").alias(\"Userid1\"), col(\"SkinID\").alias(\"SkinID1\"), \\\n                        col(\"username\").alias(\"username1\"), col(\"first_name\").alias(\"first_name1\"), \\\n                        col(\"last_name\").alias(\"last_name1\"), col(\"email\").alias(\"email1\"), \\\n                        col(\"gender\").alias(\"gender1\"), col(\"ip_address\").alias(\"ip_address1\"), \\\n                        col(\"RegDate\").alias(\"RegDate1\"), col(\"RegIP\").alias(\"RegIP1\"), \\\n                        col(\"LastIP\").alias(\"LastIP1\"), col(\"DOB\").alias(\"DOB1\"), \\\n                        col(\"Postcode\").alias(\"Postcode1\"), col(\"MobilePhone\").alias(\"MobilePhone1\"), \\\n                        col(\"Landline\").alias(\"Landline1\"), col(\"Address1\").alias(\"Address11\"), \\\n                        col(\"City\").alias(\"City1\"), col(\"County\").alias(\"County1\"), \\\n                        col(\"Country\").alias(\"Country1\"), col(\"SelfExcludedUntil\").alias(\"SelfExcludedUntil1\"), \\\n                        col(\"Status\").alias(\"Status1\")) \n  return df_new\n  "],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# This function creates and/or inserts new records to Output Table - UserSCV\ndef createOutputTable(tableName):\n  # create output table\n  df = spark.sql(\"select * from \" + tableName)\n  dateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\n\n  userSCV =  df.withColumn(\"ID\", F.monotonically_increasing_id()) \\\n    .withColumn(\"RelatedID\", lit(-1).cast(IntegerType())) \n  userSCV = userSCV.withColumn(\"EntityId\", col(\"ID\")) \n\n  # rename columns \n  userSCV = userSCV.withColumn(\"OriginalEmail\", col(\"email\")) \n  userSCV = userSCV.withColumn(\"OriginalFirstname\", col(\"first_name\")) \n  userSCV = userSCV.withColumn(\"OriginalLastname\", col(\"last_name\")) \n  userSCV = userSCV.withColumn(\"OriginalRegDate\", col(\"RegDate\"))\n  userSCV = userSCV.withColumn(\"OriginalDOB\", col(\"DOB\"))\n  userSCV = userSCV.withColumn(\"OriginalPostcode\", col(\"Postcode\"))             \n  userSCV = userSCV.withColumn(\"OriginalMobilePhone\", col(\"MobilePhone\"))\n  userSCV = userSCV.withColumn(\"OriginalAddress1\", col(\"Address1\"))            \n  #userSCV = userSCV.withColumn(\"OriginalAddress2\", col(\"Address2\"))            \n  userSCV = userSCV.withColumn(\"OriginalCity\", col(\"City\"))\n  userSCV = userSCV.withColumn(\"Firstname_Lastname_RegIP\", F.concat(col('first_name'),lit('_'), col('last_name'), lit('_'),col('RegIP') ))       \n  userSCV = userSCV.withColumn(\"Firstname_Lastname_LastIP\", \\\n                               F.concat(col('first_name'),lit('_'), col('last_name'), lit('_'),col('LastIP') ))\n  userSCV = userSCV.withColumn(\"Firstname_Lastname_Username\", \\\n                               F.concat(col('first_name'),lit('_'), col('last_name'), lit('_'),col('Username') ))\n  userSCV = userSCV.withColumn(\"Firstname_DOB_City\", F.concat(col('first_name'),lit('_'), col('DOB'), lit('_'),col('City') ))\n  userSCV = userSCV.withColumn(\"Firstname_Postcode\", F.concat(col('first_name'),lit('_'), col('Postcode')  )) \n  userSCV = userSCV.withColumn(\"Firstname_Mobilephone\", F.concat(col('first_name'),lit('_'), col('MobilePhone')  ))          \n  userSCV = userSCV.withColumn(\"DOB_Postcode\", F.concat(col('DOB'),lit('_'), col('Postcode')  )) \n  userSCV = userSCV.withColumn(\"Address1_Postcode\", F.concat(col('Address1'),lit('_'), col('Postcode')  ))              \n  userSCV = userSCV.withColumn(\"Firstname_Lastname_Address1_City\", \\\n                               F.concat(col('first_name'),lit('_'), col('last_name'), lit('_'),col('Address1'), lit('_'), col('City') ))\n  userSCV = userSCV.withColumn(\"Load_date\", lit(dateTimeStr))\n  userSCV = userSCV.withColumn(\"LastModifiedDate\", lit(dateTimeStr))\n  userSCV = userSCV.withColumn(\"CompareStatus\", lit(0))\n  userSCV = userSCV.withColumn(\"CompareStatus\", lit(None).cast(StringType()))\n  # Create a HIVE table to save Data fro Dataframe \n  if (len(spark.sql(\"SHOW TABLES LIKE '\" + \"UserSCV\"+ \"'\").collect()) == 1):\n    userSCV.write.insertInto(\"UserSCV\")\n  else:\n    userSCV.write.saveAsTable(\"UserSCV\")\n\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# This function converts the Existing User with new User records.\ndef compareData(tableName):\n  spark.sql(\"REFRESH TABLE  \" + tableName)\n  df_temp = spark.sql (\"select * from \" + tableName)\n  count = df_temp.count()\n  if (count > 0):\n    insertNewVersionOfUser(tableName)\n  "],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# streaming starts here by reading the input file \ninputPath = \"/FileStore/users/inprogress/\"\nstreamingInputDF = (\n  spark\n    .readStream\n    .schema(stream_schema)\n    .option(\"maxFilesPerTrigger\", \"1\")\n    .option(\"header\", \"true\")\n    .csv(inputPath)\n)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")  # keep the size of shuffles small\n\nquery = (\n  streamingInputDF\n    .writeStream\n    .format(\"memory\")\n    .outputMode(\"update\")\n    .queryName(\"users\")\n    .start()\n)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["def processUserInfo(df):\n  # Read the csv file as example\n  print(\"-----------------------------------------------------------------------------------\")\n  print(\"Reading streaming data\")\n  # cleanse the data\n  # Standardise the telephone number to take away -, ) from input data \n\n  df_user_updated = df.rdd.map(lambda c: fixUserRow(c))\n  # change the column type now\n  df_user = sqlContext.createDataFrame(df_user_updated, user_schema)\n  # Insert into intermediate table\n  # check if table exists\n  if (len(spark.sql(\"SHOW TABLES LIKE '\" + \"users_load\"+ \"'\").collect()) == 1):\n    df_user.write.insertInto(\"users_load\")\n  else:\n    df_user.write.saveAsTable(\"users_load\")\n\n  print(\"After saving data to userload\")\n  \n  # check if UserSCV table exists:\n  if (len(spark.sql(\"SHOW TABLES LIKE '\" + \"UserSCV\"+ \"'\").collect()) == 1) :\n    spark.sql(\"REFRESH TABLE UserSCV\")\n  else:\n    print(\"UserSCV table do not exist; hence creating it\")\n    df_new = sqlContext.createDataFrame(spark.sparkContext.emptyRDD(), user_schema)\n    df_new.createOrReplaceTempView(\"output_user\")\n    createOutputTable(\"output_user\")\n    spark.sql(\"REFRESH TABLE UserSCV\")\n    \n  # compare the data with existing data in UserSCV\n  \n  userSCV = spark.sql(\"select * from UserSCV\")\n  # 1. Rename the base columns \n  df_new =  getDataFrameFromStream(df_user, user_schema)\n  # 2. compare the data\n  # check for the minimal condition\n  # whether firstName + IP equals\n  print(\"1. checking for firstName + IP\")\n  df_criteria_min = userSCV.join(df_new, (userSCV.first_name == df_new.first_name1) & (userSCV.ip_address == df_new.ip_address1) )\n  df_criteria_min.createOrReplaceTempView(\"c1_FN_IP\") \n  compareData(\"c1_FN_IP\")\n\n  # This is to check  criteria: FirstName + username \n  print(\"2. checking for firstName + username\") \n  #df_new =  getDataFrameFromCSV(csvFilePath_new, user_schema)\n  df_criteria_fn_username = userSCV.join(df_new, (userSCV.first_name == df_new.first_name1) & (userSCV.username == df_new.username1) )\n  df_criteria_fn_username.createOrReplaceTempView(\"c1_FN_username\") \n  compareData(\"c1_FN_username\")\n\n  # check for firstName, Dob and city\n  print(\"3. checking for firstName + DOB+ City\") \n  df_criteria_fn_dob_city = userSCV.join(df_new, (userSCV.first_name == df_new.first_name1) \\\n                                     & (userSCV.DOB == df_new.DOB1) \\\n                                     & (userSCV.City == df_new.City1) )\n  df_criteria_fn_dob_city.createOrReplaceTempView(\"c1_fn_dob_city\") \n  compareData(\"c1_fn_dob_city\") \n\n  # This is to check  criteria: FirstName + postcode \n  print(\"4. checking for firstName + PostCode\") \n  df_criteria_fn_postcode = userSCV.join(df_new, (userSCV.first_name == df_new.first_name1) \\\n                                     & (userSCV.Postcode == df_new.Postcode1) )\n  df_criteria_fn_postcode.createOrReplaceTempView(\"c1_fn_postcode\") \n  compareData(\"c1_fn_postcode\")\n\n  # This is to check  criteria: DOB + postcode\n  print(\"5. checking for DOB + PostCode\") \n  df_criteria_postcode_dob = userSCV.join(df_new, (userSCV.DOB == df_new.DOB1) \\\n                                     & (userSCV.Postcode == df_new.Postcode1) )\n  df_criteria_postcode_dob.createOrReplaceTempView(\"c1_postcode_dob\") \n  compareData(\"c1_postcode_dob\")\n\n  # This is to check  criteria: Address1 + postcode \n  print(\"6. checking for Address1 + PostCode\") \n  df_criteria_postcode_addr1 = userSCV.join(df_new, (userSCV.Address1 == df_new.Address11) \\\n                                     & (userSCV.Postcode == df_new.Postcode1) )\n  df_criteria_postcode_addr1.createOrReplaceTempView(\"c1_postcode_addr1\") \n  compareData(\"c1_postcode_addr1\")\n\n  # This is to check  criteria: FirstName + LastName + Address1 + city \n  print(\"7. checking for firstName + Address1 + LastName + City\") \n  df_criteria_fn_ln_addr1_city = userSCV.join(df_new, (userSCV.first_name == df_new.first_name1) \\\n                                     & (userSCV.last_name == df_new.last_name1)\n                                     & (userSCV.Address1 == df_new.Address11) \\\n                                     & (userSCV.City == df_new.City1) )\n\n  df_criteria_fn_ln_addr1_city.createOrReplaceTempView(\"c1_fn_ln_addr1_city\") \n  compareData(\"c1_fn_ln_addr1_city\")\n\n  # check for FirstName and MobilePhone\n  print(\"8. checking for firstName + MobilePhone\") \n  df_fn_mobile = userSCV.join(df_new, (userSCV.first_name == df_new.first_name1) & (userSCV.MobilePhone == df_new.MobilePhone1) )\n  df_fn_mobile.createOrReplaceTempView(\"c1_fn_mobile\") \n  compareData(\"c1_fn_mobile\")\n\n  df_user.createOrReplaceTempView(\"output_user\")\n  createOutputTable(\"output_user\")\n    \n  \n  print(\"-----------------------------------------------------------------------------------\")\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# This function filters new data\ndef filterUpdatedDF(df_user, tracker_table):\n  if (len(spark.sql(\"SHOW TABLES LIKE '\" + tracker_table+ \"'\").collect()) == 1):\n    spark.sql(\"REFRESH TABLE \" + tracker_table)\n    tracker_df = spark.sql(\"select batch from \" + tracker_table).distinct()\n    old_batch = df_user.select(\"batch\").intersect(tracker_df)\n    df_filtered = df_user.select(\"*\").where(df_user.batch != old_batch.batch)\n    df_filtered.drop(\"batch\").createOrReplaceTempView(\"filteredView\")\n    df_filtered.select(\"batch\").distinct().write.insertInto(tracker_table)\n  else:\n    df_user.drop(\"batch\").createOrReplaceTempView(\"filteredView\")\n    df_user.select(\"batch\").distinct().write.saveAsTable(tracker_table)\n  return spark.sql(\"select * from filteredView\")\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["row_count = 0\ndef job():\n  global row_count\n  spark.sql(\"REFRESH TABLE users\")\n  stream_snap_df = spark.sql(\"select * from users\")\n  if stream_snap_df.count() > row_count:\n    total = str(stream_snap_df.count() - row_count)\n    print(\"New csv files received with {} records. Total Records received {}\".format(total, str(stream_snap_df.count())))\n    row_count = stream_snap_df.count()\n    df = filterUpdatedDF(stream_snap_df, 'batchTracker')\n    if df.count()>0:\n      processUserInfo(df)\n    else:\n      print(\"No new record received ...\")\n  else:\n    print(\"No new csv file received ...\")\n\nschedule.every(10).seconds.do(job)\n\nwhile True:\n  schedule.run_pending()\n  time.sleep(1)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["%sql select * from userSCV"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["%sql select count(*) from userSCV"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["%sql select count(*) from users"],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"SCV_streaming","notebookId":3329407362443425},"nbformat":4,"nbformat_minor":0}
